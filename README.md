# ğŸ™ï¸ Murf AI Conversational Bot

An AI-powered conversational voice agent built with **FastAPI**, **AssemblyAI**, **Google Gemini**, and **Murf AI**.  
The bot listens to your voice, transcribes it, generates intelligent responses using an LLM, and speaks back to you in a natural Murf AI voice â€” all while maintaining chat history.

---

## ğŸ“Œ Features

- **ğŸ¤ Speech-to-Text (STT)** â€” Uses **AssemblyAI** to transcribe user audio in real-time.
- **ğŸ§  Conversational AI** â€” Uses **Google Gemini (2.5-flash)** to understand and respond contextually.
- **ğŸ”Š Text-to-Speech (TTS)** â€” Uses **Murf AI** to generate natural-sounding responses.
- **ğŸ’¬ Chat History** â€” Stores and retrieves past conversation context using **SQLite**.
- **âš ï¸ Robust Error Handling** â€” Gracefully handles API failures with fallback pre-generated audio.
- **ğŸ“± Clean UI** â€” TailwindCSS-based interface for easy interaction.

---

## ğŸ› ï¸ Tech Stack

### **Frontend**
- HTML, TailwindCSS
- Vanilla JavaScript
- Fetch API for communication with backend

### **Backend**
- FastAPI (Python)
- SQLite for chat history
- AssemblyAI SDK for speech-to-text
- Google Gemini API for LLM responses
- Murf AI API for text-to-speech

---

## ğŸ—ï¸ Architecture

```text
ğŸ¤ User Audio
   â†“ (Browser mic)
Frontend (bot.js)
   â†“ POST /agent/chat/{session_id}
FastAPI Backend
   â†“ STT (AssemblyAI)
   â†“ Append to SQLite chat history
   â†“ LLM Response (Google Gemini)
   â†“ Append response to chat history
   â†“ TTS (Murf AI)
   â†“ Return transcription + LLM text + audio URL
Frontend
   â†“ Play bot audio & display chat bubbles
```


---

# ğŸ“‚ Project Structure

```text
/project-root
â”‚â”€â”€ bot.html              # Conversational bot UI
â”‚â”€â”€ bot.js                # Frontend logic
â”‚â”€â”€ main.py               # FastAPI backend
â”‚â”€â”€ db_utils.py           # SQLite database helpers
â”‚â”€â”€ /data                 # SQLite DB file stored here
â”‚â”€â”€ /static               # Static JS/CSS files
â”‚â”€â”€ README.md             # Project documentation
```

---

# âš™ï¸ Environment Variables
Before running the project, create a .env file in the root with:

```text
ASSEMBLYAI_API_KEY=your_assemblyai_api_key
GEMINI_API_KEY=your_gemini_api_key
MURF_API_KEY=your_murf_api_key
MURF_API_URL=murf_endpoint_url
```

---

# ğŸš€ How to Run

### 1ï¸âƒ£ Clone the repository
```terminaloutput
git clone https://github.com/your-username/murf-ai-bot.git
cd murf-ai-bot
```

### 2ï¸âƒ£ Install dependencies
Itâ€™s recommended to use a virtual environment:
```text
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows
pip install -r requirements.txt
```

### 3ï¸âƒ£ Create .env file
Add your API keys:
```text
ASSEMBLYAI_API_KEY=your_assemblyai_api_key
GEMINI_API_KEY=your_gemini_api_key
MURF_API_KEY=your_murf_api_key
MURF_API_URL=murf_endpoint_url
```

### 4ï¸âƒ£ Run the FastAPI server
```terminaloutput
uvicorn main:app --reload
```

### 5ï¸âƒ£ Open in browser
Navigate to: http://localhost:8000/
